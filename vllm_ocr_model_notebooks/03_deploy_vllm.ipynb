{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53189d6e-6842-4936-862e-d820eb725266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh \n",
    "apt update\n",
    "apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef543d35-d226-47c2-b9ca-680d6c863146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6a29c6e-71e3-44be-8402-ee306d820c51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "with open(\"../configs/olmocr_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "catalog_name = config.get(\"catalog_name\")\n",
    "schema_name = config.get(\"schema_name\")\n",
    "volume_name = config.get(\"volume_name\")\n",
    "volume_folder = config.get(\"volume_folder\")\n",
    "model_name = config.get(\"model_name\")\n",
    "revision = config.get(\"revision\")\n",
    "\n",
    "cache_volume =  f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/{model_name}/{revision}/{volume_folder}\"\n",
    "cache_hf = \"/local_disk0/hf_cache\"\n",
    "cache_local = f\"/local_disk0/{volume_folder}\" \n",
    "\n",
    "os.environ[\"HF_HOME\"] = cache_hf\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_hf\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"True\"\n",
    "os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"1000\"\n",
    "# os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'  # Enables optimized download backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8d4050-0e5f-480b-aca7-8892fdb322f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Copy volume cache to local cache if not already there\n",
    "if not os.path.exists(cache_local):\n",
    "    try: \n",
    "        print(f\"Loading model from {cache_volume} to {cache_local}.\")\n",
    "        snapshots_dir = '/'.join(cache_local.split('/')[:-1])\n",
    "        if not os.path.exists(snapshots_dir):\n",
    "            os.makedirs(snapshots_dir)\n",
    "        \n",
    "        shutil.copytree(cache_volume, cache_local) \n",
    "        print(f\"Successfully loaded model from {cache_volume} to {cache_local}!\")\n",
    "    except Exception as e: \n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(f\"File already exists locally at {cache_local}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "831c0dd4-3c13-4e6a-a5da-c630a731478b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install qwen-vl-utils[decord]==0.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af2a9d5-1bc8-4010-aa6b-b3f1f91c9537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    Qwen2_5_VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    "    AutoModelForImageTextToText\n",
    ")\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import mlflow.pyfunc\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "class OlmocrPyfunc(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "\n",
    "        self.model_id = context.artifacts[\"model-weights\"]\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.dtype = torch.bfloat16 if self.device == \"cuda\" else torch.float32\n",
    "\n",
    "        print(\"************************************\")\n",
    "        print(f\"Device: {self.device}, dtype: {self.dtype}\")\n",
    "        print(f\"Loading model {self.model_id} to {self.device}\")\n",
    "        print(\"************************************\")\n",
    "\n",
    "        self.processor = AutoProcessor.from_pretrained(self.model_id)\n",
    "\n",
    "        self.model = AutoModelForImageTextToText.from_pretrained(\n",
    "            self.model_id, torch_dtype=self.dtype, device_map=\"auto\"\n",
    "        )\n",
    "\n",
    "    def predict(self, model_input: pd.DataFrame, params: dict = None) -> pd.Series:\n",
    "      outputs = []\n",
    "      max_tokens = params.get(\"max_tokens\", 1024) if params else 1024\n",
    "\n",
    "      for _, row in model_input.iterrows():\n",
    "          system_prompt = row.get(\n",
    "              \"system_prompt\",\n",
    "              \"You are a helpful assistant that extracts text from PDF images.\",\n",
    "          )\n",
    "          user_prompt = row.get(\"user_prompt\", \"\")\n",
    "\n",
    "          try:\n",
    "              image_base64 = user_prompt[\"image\"]\n",
    "              image_data = base64.b64decode(image_base64)\n",
    "              image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
    "          except Exception as e:\n",
    "              outputs.append(f\"Error processing image: {str(e)}\")\n",
    "              continue\n",
    "\n",
    "          messages = [\n",
    "              {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system_prompt}]},\n",
    "              {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": [\n",
    "                      {\"type\": \"image\", \"image\": image},\n",
    "                      {\"type\": \"text\", \"text\": user_prompt[\"text\"]},\n",
    "                  ],\n",
    "              },\n",
    "          ]\n",
    "          \n",
    "          text = self.processor.apply_chat_template(\n",
    "              messages, tokenize=False, add_generation_prompt=True\n",
    "          )\n",
    "\n",
    "          image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "          inputs = self.processor(  \n",
    "              text=[text],\n",
    "              images=image_inputs,\n",
    "              videos=video_inputs,\n",
    "              padding=True,\n",
    "              return_tensors=\"pt\",\n",
    "          ).to(self.device)\n",
    "\n",
    "          prompt_len = inputs[\"input_ids\"].size(-1)\n",
    "\n",
    "          with torch.inference_mode():\n",
    "              generation = self.model.generate(**inputs, max_new_tokens=max_tokens)\n",
    "\n",
    "          generated_tokens = generation[0][prompt_len:]\n",
    "          \n",
    "          output_text = self.processor.batch_decode(\n",
    "              generated_tokens.unsqueeze(0),  \n",
    "              skip_special_tokens=True,\n",
    "              clean_up_tokenization_spaces=False,\n",
    "          )[0]  \n",
    "          \n",
    "          outputs.append(output_text)\n",
    "\n",
    "      return pd.Series(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcce9dda-a05a-4d34-86ad-4652b0c31499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "url = \"https://arxiv.org/pdf/2502.13923\"\n",
    "response = requests.get(url)\n",
    "pdf_bytes = response.content\n",
    "    \n",
    "pil_images = convert_from_bytes(pdf_bytes)\n",
    "\n",
    "img = pil_images[0]\n",
    "buffer = BytesIO()\n",
    "img.save(buffer, format=\"PNG\")\n",
    "image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "system_prompt=\"You are a helpful assistant that extracts text from PDF images.\"\n",
    "prompt = \"Extract the entire text from the abstract section in this image.\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"system_prompt\": [system_prompt],\n",
    "    \"user_prompt\": [\n",
    "        {\n",
    "            \"text\": prompt,\n",
    "            \"image\": image_base64\n",
    "        }\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232b640f-dcc0-4244-90e1-0264652febeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, artifacts):\n",
    "        self.artifacts = artifacts\n",
    "\n",
    "olmocr = OlmocrPyfunc()\n",
    "olmocr.load_context(Context({\"model-weights\": cache_local}))\n",
    "\n",
    "output = olmocr.predict(df, params={\"max_tokens\": 512})\n",
    "\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed1fb5f-25be-45d2-8a52-b96ac87c1a8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Log to mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d6da98-6132-4c4b-959b-7078b3e722ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0f49dfc-2aaa-4df6-b5f3-203c5d11a9a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "signature = infer_signature(\n",
    "  model_input=df, \n",
    "  model_output=output,\n",
    "  params={\"max_tokens\": 512}\n",
    "  ) # Doing strict schema to avoid rerunning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b9da7ca-3933-4a7f-969f-5ed020c1a8b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"olmocr_pyfunc\",\n",
    "        python_model=OlmocrPyfunc(),\n",
    "        signature=signature,\n",
    "        # conda_env=\"conda.yaml\",\n",
    "        pip_requirements=[\n",
    "            \"torch==2.6.0\",\n",
    "            \"transformers==4.55.4\",\n",
    "            \"accelerate==1.10.1\",\n",
    "            \"huggingface_hub==0.34.4\",\n",
    "            \"Pillow==11.3.0\",\n",
    "            \"flask==3.1.2\",\n",
    "            \"bitsandbytes==0.47.0\",\n",
    "            \"pdf2image==1.17.0\",\n",
    "            \"qwen-vl-utils==0.0.8\"\n",
    "        ],\n",
    "        # extra_pip_requirements=package_versions,  \n",
    "        artifacts={\n",
    "            'model-weights': cache_local},\n",
    "        input_example = df\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f5298c2-ef90-40ba-8162-52a85968167b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "served_model_name = \"olmocr_hf_deployment\"\n",
    "uc_model_name = f\"{catalog_name}.{schema_name}.{served_model_name}\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=model_info.model_uri,\n",
    "    name=uc_model_name\n",
    ")\n",
    "\n",
    "print(f\"Registered model version: {result.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030dabd7-f0d7-4a68-9e16-5f0a02ebcdb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.set_registered_model_alias(\n",
    "    name=uc_model_name,\n",
    "    alias=\"Challenger\",\n",
    "    version=result.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08eaf180-c82b-48d2-a670-3ad8af80e0a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow \n",
    "model_uri = f\"models:/{uc_model_name}@Challenger\"\n",
    "print(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad93fb49-284a-4af6-af9c-cafbda133a79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test the model first and then promote to Challenge\n",
    "TODO: Modify code with appropriate usage of VRAM on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c25ab523-4050-454f-a510-c370c768885f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "served_model_name = \"olmocr_hf_deployment\"\n",
    "uc_model_name = f\"{catalog_name}.{schema_name}.{served_model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b089da-ef58-47b3-93b4-d1c009a1b13c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client.set_registered_model_alias(\n",
    "    name=uc_model_name,\n",
    "    alias=\"Champion\",\n",
    "    version=result.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cb4ad5c-8417-41ec-aa22-57ead6f62ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_info = client.get_model_version_by_alias(uc_model_name, \"Champion\")\n",
    "model_name = model_info.name\n",
    "model_version = model_info.version\n",
    "served_entity_name = served_model_name\n",
    "user_email = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dc3a440-2b89-4392-af54-107667f414ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For Azure, we will use GPU LARGE \n",
    "# May need multi-gpu A10s for AWS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa5d0fb1-0989-4dd6-aa70-95f30c920d7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b1f5aae-c197-411f-93eb-358b3013340e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import (\n",
    "        EndpointCoreConfigInput,\n",
    "        ServedEntityInput,\n",
    "        AutoCaptureConfigInput,\n",
    "        ServingEndpointDetailed,\n",
    "        EndpointTag\n",
    "    )\n",
    "\n",
    "served_entities = [\n",
    "    ServedEntityInput(\n",
    "        entity_name=model_name,\n",
    "        entity_version=model_version,\n",
    "        name=served_entity_name,\n",
    "        workload_type=\"GPU_LARGE\",\n",
    "        workload_size=\"Small\",\n",
    "        scale_to_zero_enabled=True,\n",
    "    )\n",
    "]\n",
    "auto_capture_config = AutoCaptureConfigInput(\n",
    "    catalog_name=catalog_name,\n",
    "    schema_name=schema_name,\n",
    "    table_name_prefix=f\"{model_name}_serving\",\n",
    "    enabled=True,\n",
    ")\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "endpoint_details = w.serving_endpoints.create_and_wait(\n",
    "            name=f\"{served_entity_name}_endpoint\",\n",
    "            config=EndpointCoreConfigInput(\n",
    "                name=f\"{served_entity_name}_endpoint\",\n",
    "                served_entities=served_entities,\n",
    "                auto_capture_config=None\n",
    "            ),\n",
    "            tags=[\n",
    "                EndpointTag(key=\"application\", value=served_entity_name),\n",
    "                EndpointTag(key=\"created_by\", value=user_email)\n",
    "            ],\n",
    "            timeout = timedelta(minutes=180) # wait up to three hours\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12c22bfb-9ffc-414f-8299-85e7d91462dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce320fb-2602-4091-9ee6-5b5e1310d436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "databricks_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = databricks_token\n",
    "\n",
    "endpoint_url = \"CHANGE_ME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "091dc325-2880-4e43-b01b-fe3da81c7530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "url = \"https://arxiv.org/pdf/2502.13923\"\n",
    "response = requests.get(url)\n",
    "pdf_bytes = response.content\n",
    "    \n",
    "pil_images = convert_from_bytes(pdf_bytes)\n",
    "system_prompt=\"You are a helpful assistant that extracts text from PDF images.\"\n",
    "prompt = \"Extract the entire text from the abstract section in this image.\"\n",
    "\n",
    "img = pil_images[0]\n",
    "buffer = BytesIO()\n",
    "img.save(buffer, format=\"PNG\")\n",
    "image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"system_prompt\": [system_prompt],\n",
    "    \"user_prompt\": [\n",
    "        {\n",
    "            \"text\": prompt,\n",
    "            \"image\": image_base64\n",
    "        }\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a30c33e-9e0a-4df5-a40d-d194ffb664d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "    return {'inputs': {name: data[name].tolist() for name in data.keys()} if isinstance(data, dict) else data.tolist()}\n",
    "\n",
    "def score_model(dataset):\n",
    "    url = endpoint_url,\n",
    "    headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN\")}', 'Content-Type': 'application/json'}\n",
    "    ds_dict = {'dataframe_split': dataset.to_dict(orient='split')} if isinstance(dataset, pd.DataFrame) else create_tf_serving_json(dataset)\n",
    "    data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f853a25f-565c-4a69-8368-66672987a7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score_model(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d103b8c4-4a87-4874-97ee-97688e7857e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Restart kernel to clear VRAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3270247-490a-4558-bdc4-3741579f202c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfaca348-18a1-4ff4-a8ee-5037389a935e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Optional: Test Registered Model \n",
    "Note: Careful of VRAM consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a25d7d14-b8db-443c-b8ab-f90fead98253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85142ba6-b814-4d20-a209-bf47a66d3589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "url = \"https://arxiv.org/pdf/2502.13923\"\n",
    "response = requests.get(url)\n",
    "pdf_bytes = response.content\n",
    "    \n",
    "pil_images = convert_from_bytes(pdf_bytes)\n",
    "\n",
    "img = pil_images[0]\n",
    "buffer = BytesIO()\n",
    "img.save(buffer, format=\"PNG\")\n",
    "image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "system_prompt=\"You are a helpful assistant that extracts text from PDF images.\"\n",
    "prompt = \"Extract the entire text from the abstract section in this image.\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"system_prompt\": [system_prompt],\n",
    "    \"user_prompt\": [\n",
    "        {\n",
    "            \"text\": prompt,\n",
    "            \"image\": image_base64\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "outputs = loaded_model.predict(df, params={\"max_tokens\": 512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a72d4b1-0116-45b2-be61-03c55c2a66dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(str(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8e2c172-56cc-41eb-9167-81a21306f61e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "img = pil_images[0]\n",
    "buffer = io.BytesIO()\n",
    "img.save(buffer, format=\"PNG\")\n",
    "image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"system_prompt\": [system_prompt],\n",
    "    \"user_prompt\": [\n",
    "        {\n",
    "            \"text\": prompt,\n",
    "            \"image\": image_base64\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "outputs = loaded_model.predict(df, params={\"max_tokens\": 512})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6040444310335074,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_deploy_vllm",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
